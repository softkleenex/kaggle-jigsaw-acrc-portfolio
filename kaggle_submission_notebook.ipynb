{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jigsaw ACRC - Baseline Submission\n",
    "\n",
    "**Model**: TF-IDF + LightGBM  \n",
    "**CV AUC**: 0.614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Sample submission shape: {sample_sub.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_text(df):\n",
    "    \"\"\"Combine all text features into one\"\"\"\n",
    "    combined = (\n",
    "        df['body'].fillna('') + ' [SEP] ' +\n",
    "        df['rule'].fillna('') + ' [SEP] ' +\n",
    "        df['positive_example_1'].fillna('') + ' [SEP] ' +\n",
    "        df['positive_example_2'].fillna('') + ' [SEP] ' +\n",
    "        df['negative_example_1'].fillna('') + ' [SEP] ' +\n",
    "        df['negative_example_2'].fillna('')\n",
    "    )\n",
    "    return combined\n",
    "\n",
    "# Create combined text features\n",
    "X_train_text = create_combined_text(train)\n",
    "X_test_text = create_combined_text(test)\n",
    "y_train = train['rule_violation']\n",
    "\n",
    "print(f\"Training samples: {len(X_train_text)}\")\n",
    "print(f\"Test samples: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF features: {X_train_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store OOF predictions\n",
    "oof_preds = np.zeros(len(X_train_text))\n",
    "test_preds = np.zeros(len(X_test_text))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_tfidf, y_train), 1):\n",
    "    print(f\"\\nFold {fold}/{n_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_tr = X_train_tfidf[train_idx]\n",
    "    y_tr = y_train.iloc[train_idx]\n",
    "    X_val = X_train_tfidf[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        n_estimators=1000,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc'\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_preds += model.predict_proba(X_test_tfidf)[:, 1] / n_folds\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "    cv_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold} AUC: {fold_auc:.6f}\")\n",
    "\n",
    "# Overall CV score\n",
    "overall_auc = roc_auc_score(y_train, oof_preds)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Overall CV AUC: {overall_auc:.6f}\")\n",
    "print(f\"Mean CV AUC: {np.mean(cv_scores):.6f} (+/- {np.std(cv_scores):.6f})\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test['row_id'],\n",
    "    'rule_violation': test_preds\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Min: {submission['rule_violation'].min():.6f}\")\n",
    "print(f\"  Max: {submission['rule_violation'].max():.6f}\")\n",
    "print(f\"  Mean: {submission['rule_violation'].mean():.6f}\")\n",
    "print(f\"  Median: {submission['rule_violation'].median():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
